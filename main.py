from fastapi import FastAPI, Body
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Union
import torch
from model_loader import load_model_and_vocab
from threading import Lock
import math
import random
import json
import os
import logging

# Loglama ayarlarÄ±
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class PredictRequest(BaseModel):
    vagon_no: str
    vagon_tipi: str
    komponent: str
    activation_time: Union[str, None] = None

class ConfirmRequest(BaseModel):
    vagon_no: str

class CompleteRequest(BaseModel):
    vagon_no: str
    vagon_tipi: str
    komponent: str
    neden: str
    istasyon: str
    completion_time: Union[str, None] = None
    activation_time: Union[str, None] = None

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

config = {
    "max_len": 128,
    "embed_size": 384,
    "num_heads": 6,
    "num_layers": 10,
    "ff_dim": 768,
    "dropout": 0.15,
    "softmax_temp": 1.1
}

base_dir = "."
data_dir = f"{base_dir}/data"
model_path = f"{base_dir}/transformer_rl.pt"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model, vocab, id2label = load_model_and_vocab(model_path, data_dir, config, device)

station_capacity = {ist: 5 for ist in id2label.values()}
capacity_lock = Lock()
pending_predictions = []

ACTIVE_REPAIRS_FILE = "aktif_bakimlar.json"
COMPLETED_REPAIRS_FILE = "tamamlanan_bakimlar.json"

if not os.path.exists(ACTIVE_REPAIRS_FILE):
    with open(ACTIVE_REPAIRS_FILE, "w") as f:
        json.dump({}, f)

if not os.path.exists(COMPLETED_REPAIRS_FILE):
    with open(COMPLETED_REPAIRS_FILE, "w") as f:
        json.dump([], f)

def encode_input(data: PredictRequest, vocab, max_len=128):
    input_ids = [
        vocab.get("__cls__", 0),
        vocab.get(data.vagon_no, 0),
        vocab.get(data.vagon_tipi, 0),
        vocab.get(data.komponent, 0)
    ]
    return input_ids + [0] * (max_len - len(input_ids))

@app.post("/predict")
def predict(req: PredictRequest):
    try:
        # Ã–nce vagonun aktif bakÄ±mda olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        with open(ACTIVE_REPAIRS_FILE, "r") as f:
            active_data = json.load(f)
            for station_repairs in active_data.values():
                for repair in station_repairs:
                    if repair["vagon_no"] == req.vagon_no:
                        logging.warning(f"Vagon {req.vagon_no} zaten aktif bakÄ±mda.")
                        raise ValueError("Bu vagon zaten aktif bir bakÄ±mda bulunmaktadÄ±r. LÃ¼tfen baÅŸka bir vagon seÃ§iniz.")

        input_ids = encode_input(req, vocab, config["max_len"])
        input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)

        with torch.no_grad():
            logits = model(input_tensor) / config["softmax_temp"]
            probs = torch.softmax(logits, dim=-1).squeeze()
            top_indices = torch.argsort(probs, descending=True).tolist()

        # Aktif bakÄ±mlarÄ± kontrol et
        with open(ACTIVE_REPAIRS_FILE, "r") as f:
            data = json.load(f)

        # En uygun istasyonu bul
        assigned = None
        confidence = None
        preferred_station = id2label[top_indices[0]]
        preferred_confidence = probs[top_indices[0]].item()

        for idx in top_indices:
            station = id2label[idx]
            if station not in data or len(data[station]) < 5:
                assigned = station
                confidence = probs[idx].item()
                break

        if assigned is None:
            assigned = preferred_station
            confidence = preferred_confidence

        component_priority_map = {
            "TekerleÄŸin Bandaj KÄ±smÄ±": 5,
            "Fren PnÃ¶matik KÄ±sÄ±m": 4,
            "Sabo": 3,
            "Boden": 2,
            "KapÄ± ve SÃ¼rme Duvar": 5,
            "Dikme (Platform Vagon)": 2,
            "Yan veya AlÄ±n Duvar (AÃ§Ä±k Vagon)": 2,
            "Fren Mekanik KÄ±sÄ±m": 4,
            "Duvar": 2,
            "YarÄ± Otomatik KoÅŸum TakÄ±mÄ±": 3,
            "Yan Duvar KapaÄŸÄ± (Platform Vagon)": 3,
            "Basamak/Tutamak/Merdiven/GeÃ§it/Korkuluk/YazÄ± LevhalarÄ± vb. DeÄŸiÅŸik ParÃ§alar": 2,
            "Yaprak Susta": 4,
            "Boji Yan YastÄ±k ve SustasÄ±": 4,
            "Branda Kilitleme TertibatÄ± (Rils vb) (Ã–zel TertibatlÄ± Vagon)": 2,
            "Ã‡atÄ± ve Su SÄ±zdÄ±rmazlÄ±ÄŸÄ± (KapalÄ± Vagon)": 2,
            "Dikme DesteÄŸi (Platform Vagon)": 2,
            "Y 25 Bojinin SÃ¼spansiyon Sistemi": 5,
            "Topraklama Kablosu": 3,
            "SÃ¼spansiyon BaÄŸlantÄ±larÄ±": 4,
            "El Freni": 4,
            "Taban": 3,
            "Dingil Kutusu": 5,
            "Vagon GÃ¶vdesi Ä°skeleti": 4,
            "YÃ¼kÃ¼n DaÄŸÄ±lÄ±mÄ±": 2,
            "Kapama TertibatÄ±/Tespit Sportu (KapalÄ± Vagon)": 3,
            "ACTS Konteyner Vagonu (Ã–zel TertibatlÄ± Vagon)": 3,
            "MenteÅŸe/Pim/Sabitleme CivatasÄ± (Platform Vagon)": 3,
            "HavalandÄ±rma KapaÄŸÄ± (KapalÄ± Vagon)": 2,
            "Helezon Susta": 4,
            "Dingilli Vagonlarda SÃ¼spansiyon Sportu": 4,
            "Monoblok Tekerlek": 5,
            "AlÄ±n KapaklarÄ±n KapatÄ±lmasÄ± ve Ã‡alÄ±ÅŸtÄ±rÄ±lmasÄ± TertibatÄ± (AÃ§Ä±k Vagon)": 3,
            "BoÅŸi Åžasisi": 3,
            "Tampon PlakasÄ±": 3,
            "Vagon Åžasesi": 4,
            "Vagon Ãœzerindeki YazÄ± ve Ä°ÅŸaretler": 2,
            "Konteyner VagonlarÄ± Ãœzerindeki YÃ¼k Ãœnitelerinin Emniyete AlÄ±nmasÄ±na YÃ¶nelik Tertibat": 2,
            "Payanda, Kalas, Gerdirme, BaÄŸlantÄ± TertibatÄ±": 2,
            "Ã–zellikle Yatay veya DÃ¼ÅŸey AktarÄ±m iÃ§in KullanÄ±lan Ã–zel Ekipman": 2,
            "DoÄŸrudan veya DolaylÄ± BaÄŸlantÄ±": 3,
            "Dingil": 5,
            "BandajlÄ± Tekerlek": 5,
            "Dingil Ã‡atalÄ± AÅŸÄ±nma PlakasÄ±": 3,
            "Dikme": 2,
            "Vagon DuvarÄ± veya KenarÄ±": 3,
            "Tekerlek GÃ¶vdesi": 5,
            "Ä°ÅŸletme BozukluklarÄ±": 4,
            "Vagon GÃ¶vdesi Ä°Ã§ DonanÄ±mÄ±": 3,
            "Y Bojide ManganlÄ± AÅŸÄ±nma PlakasÄ±": 4,
            "Dingil Ã‡atalÄ± BaÄŸlantÄ± Pernosu": 3,
            "Paketleme, YÃ¼k BaÄŸlama.": 2,
        }

        component_level = component_priority_map.get(req.komponent, 3)
        label_level = random.randint(1, 5)  # Rastgele Ã¶ncelik seviyesi

        priority = math.ceil(math.sqrt(component_level * label_level))
        priority = max(1, min(5, priority))

        neden = f"{req.komponent} arÄ±zasÄ± nedeniyle tamire alÄ±ndÄ±."

        logging.info(f"Tahmin yapÄ±ldÄ±: {req.vagon_no} iÃ§in {assigned} istasyonuna atandÄ±.")
        return {
            "vagon_no": req.vagon_no,
            "vagon_tipi": req.vagon_tipi,
            "komponent": req.komponent,
            "prediction": assigned,
            "confidence": round(confidence, 4),
            "priority": priority,
            "neden": neden,
            "preferred_station": preferred_station if assigned != preferred_station else None,
            "preferred_confidence": round(preferred_confidence, 4) if assigned != preferred_station else None
        }
    except ValueError as ve:
        logging.error(str(ve))
        raise
    except Exception as e:
        logging.error(f"Tahmin sÄ±rasÄ±nda hata oluÅŸtu: {e}")
        raise

@app.post("/activate_repair")
def activate_repair(req: PredictRequest):
    try:
        input_ids = encode_input(req, vocab, config["max_len"])
        input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)

        with torch.no_grad():
            logits = model(input_tensor) / config["softmax_temp"]
            probs = torch.softmax(logits, dim=-1).squeeze()
            top_indices = torch.argsort(probs, descending=True).tolist()

        with open(ACTIVE_REPAIRS_FILE, "r+") as f:
            data = json.load(f)

            # Vagon zaten aktif bakÄ±mda mÄ± kontrol et
            already_exists = any(
                r["vagon_no"] == req.vagon_no
                for repairs in data.values()
                for r in repairs
            )
            if already_exists:
                logging.warning(f"Vagon {req.vagon_no} zaten aktif bakÄ±mda.")
                return {"message": "Zaten aktif bakÄ±mda."}

            # En uygun istasyonu bul
            assigned = None
            confidence = None
            preferred_station = id2label[top_indices[0]]
            preferred_confidence = probs[top_indices[0]].item()

            for idx in top_indices:
                station = id2label[idx]
                if station not in data or len(data[station]) < 5:
                    assigned = station
                    confidence = probs[idx].item()
                    break

            if assigned is None:
                logging.warning("TÃ¼m istasyonlar dolu.")
                return {"message": "TÃ¼m istasyonlar dolu. LÃ¼tfen daha sonra tekrar deneyin."}

            if assigned not in data:
                data[assigned] = []
            data[assigned].append({
                "vagon_no": req.vagon_no,
                "vagon_tipi": req.vagon_tipi,
                "komponent": req.komponent,
                "prediction": assigned,
                "confidence": round(confidence, 4),
                "neden": f"{req.komponent} arÄ±zasÄ± nedeniyle tamire alÄ±ndÄ±.",
                "activation_time": req.activation_time,
                "preferred_station": preferred_station if assigned != preferred_station else None,
                "preferred_confidence": round(preferred_confidence, 4) if assigned != preferred_station else None
            })

            f.seek(0)
            json.dump(data, f, indent=2)
            logging.info(f"BakÄ±m aktivasyonu yapÄ±ldÄ±: {req.vagon_no} iÃ§in {assigned} istasyonuna atandÄ±.")
            return {
                "message": "BakÄ±m baÅŸarÄ±yla aktive edildi.",
                "assigned_station": assigned,
                "preferred_station": preferred_station if assigned != preferred_station else None
            }
    except Exception as e:
        logging.error(f"BakÄ±m aktivasyonu sÄ±rasÄ±nda hata oluÅŸtu: {e}")
        raise

@app.get("/active_repairs")
def get_active_repairs():
    with open(ACTIVE_REPAIRS_FILE) as f:
        return json.load(f)

@app.get("/history")
def get_history(vagon_no: str):
    try:
        with open(COMPLETED_REPAIRS_FILE, "r") as f:
            data = json.load(f)
        return [item for item in data if item["vagon_no"] == vagon_no]
    except Exception as e:
        logging.error(f"GeÃ§miÅŸ bakÄ±m verisi alÄ±namadÄ±: {e}")
        return []

@app.post("/complete_repair")
def complete_repair(req: CompleteRequest):
    with open(ACTIVE_REPAIRS_FILE, "r+") as f:
        data = json.load(f)
        if req.istasyon in data:
            data[req.istasyon] = [r for r in data[req.istasyon] if r["vagon_no"] != req.vagon_no]
            if not data[req.istasyon]:
                del data[req.istasyon]
            f.seek(0)
            json.dump(data, f, indent=2)
            f.truncate()

    completed = {
        "vagon_no": req.vagon_no,
        "vagon_tipi": req.vagon_tipi,
        "komponent": req.komponent,
        "neden": req.neden,
        "istasyon": req.istasyon,
        "completion_time": req.completion_time,
        "activation_time": req.activation_time
    }

    with open(COMPLETED_REPAIRS_FILE, "r+") as f:
        tamamlanan = json.load(f)
        tamamlanan.append(completed)
        f.seek(0)
        json.dump(tamamlanan, f, indent=2)
        f.truncate()

    return {"message": "BakÄ±m tamamlandÄ±."}

@app.post("/reset_capacity")
def reset_capacity():
    global station_capacity
    with capacity_lock:
        station_capacity = {ist: 5 for ist in id2label.values()}
    return {"message": "Kapasiteler sÄ±fÄ±rlandÄ± ðŸŽ¯"}

@app.get("/capacities")
def get_capacities():
    return station_capacity

@app.get("/")
def root():
    return {"message": "Model API aktif ðŸŽ¯"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=int(os.environ.get("PORT", 10000)))
